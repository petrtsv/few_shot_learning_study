\documentclass[a4paper, 12pt]{report}

\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage[T2A]{fontenc}
\usepackage{indentfirst}
\usepackage{misccorr}
\usepackage{float}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{gensymb}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\graphicspath{{./assets/}}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage[nottoc,numbib]{tocbibind}

\makeatletter
\def\@makechapterhead#1{%
  % \vspace*{50\p@}%
  {\parindent \z@ \raggedright \normalfont
    \ifnum \c@secnumdepth >\m@ne
      \if@mainmatter
        %\huge\bfseries \@chapapp\space \thechapter
        \Huge\bfseries \thechapter.\space%
        %\par\nobreak
        %\vskip 20\p@
      \fi
    \fi
    \interlinepenalty\@M
    \Huge \bfseries #1\par\nobreak
    \vskip 40\p@
  }}
\makeatother
\begin{document}

\begin{titlepage}
	\centering
	\includegraphics[width=0.05\textwidth]{pths}\par\vspace{0.5cm}
	{\scshape\Large  Академический~лицей «Физико-техническая~школа» им.~Ж.~И.~Алфёрова \par}
	\vspace{1.0cm}
	{\scshape\large Отчет о практике \par}
	\vspace{3cm}
	{\huge\bfseries Few-Shot~Learning при~большом~числе~классов \par}
	\vspace{3cm}
	{\large Ученик: Цветков Петр (11 А класс) \par}
	\vspace{0.25cm}
	{\large Научный руководитель: Шпильман Алексей Александрович \par}


	\vfill

% Bottom of the page
	{\large Санкт-Петербург, 2020 год\par}
\end{titlepage}
	
	\begin{abstract}
	Few-Shot Learning (FSL) - активно исследуемая в наше время задача в области компьютерного зрения, подразумевающая классификацию изображений на основе малого числа примеров. В данной работе, помимо традиционного сценария FSL (5 классов, по 1 или 5 примеров на класс), рассматривается усложненная и более приближенная к практике версия задачи, в котором количество классов много больше, чем число образцов для каждого класса (100 классов, по 5 примеров на класс), а так же задача применения опыта, полученного из одного датасета, к другому. Для этого был выбран метод решения, основанных на т. н. ProtoNet Classifier \cite{closerlook}. Были проанализированы современные исследования в этой области, описанные в них модели реализованы, по-разному скомбинированы и протестированы в описанных сценариях. Для оценки использовался как популярный среди исследователей датасет miniImageNet \cite{imagenet}, так и собранный самостоятельно для многоклассовой задачи датасет, представляющий собой подмножество GoogleLandmarks \cite{google}. В результате работы были определены наиболее эффективные методы решения FSL для различных сценариев, что может быть полезно как при будущих исследованиях, так и при создании промышленных решений в области компьютерного зрения.
	\end{abstract}
	
	\tableofcontents

\chapter{Введение}

Задача классификации изображений является базовой в компьютерном зрении. С появлением сверточных нейронных сетей в этой области произошел прорыв - в 2012 году нейросеть AlexNet достигла на датасете ImageNet (1.2 млн изображений, разделенных на 1000 классов) результата в 15.3\% ошибок (приблизительно на 10\% ниже, чем 2 место). В последующие годы более сложные модели уже превзошли в этой задаче человека - в 2017 году ошибка на ImageNet составляла уже около 2.5\% - 3\% (у человека - 5\%), в связи с чем соревнование по классификации изображений по данному сценарию перестало проводиться. \\

Однако для обучения нейросетей были использованы миллионы примеров, в то время как человек умеет различать объекты основываясь всего на нескольких примерах - например, один раз посмотрев на фотографию автомобиля, мы без труда сможем узнать такой же на улице. Упомянутым выше алгоритмам потребовалось бы проанализировать сотни фотографий, чтобы отличать этот автомобиль от других. Кроме того, традиционные модели для классификации изображений не могут быть легко расширены на новые классы - нейросеть придется доучивать на новом наборе данных. \\

Эти проблемы исследователи решают в рамках задачи Few-Shot Learning (в переводе - <<обучение на малочисленных кадрах>>), сокращенно FSL. Ее можно сформулировать так: необходимо для поданных на вход изображений определить, к какому классу они относятся, опираясь лишь на несколько (1 - 5 штук) примеров к каждому классу. Такая задача намного труднее, чем традиционная классификация, так как количество доступных данных уменьшается в десятки раз. \\

Исследования в области Few-Shot Learning позволяют создать более универсальные алгоритмы, не требующие перенастройки и сбора большого количество данных для адаптации к новым задачам.Такие модели могут применяться при обработке созданных людьми изображений (например, при анализе фотографий в социальных сетях) или при создании автономных роботов (например, дронов-беспилотников и самоуправляемых автомобилей).

\chapter{Обзор существующих решений}

В статье <<A Closer Look at Few-shot Classification>> \cite{closerlook} приводится описание различных известных методов решения задачи FSL, которые глобально работают по одной схеме - используют полный датасет из известных классов, чтобы научиться адаптироваться к новым классам с малым количеством примеров. Эти методы могут быть разделены на 4 группы:

\begin{itemize}
\item \textbf{Дообучение.} Устройство моделей то же, что и в обычных (не FSL) задачах классификации. Модели обучаются на известных классах. Затем, верхние слои <<замораживаются>>, а нижние дообучаются на малочисленных примерах новых классах. Такой подход не является гибким - модель приходится постоянно обучать, что требует ощутимо больше ресурсов, чем использование обученной модели. Примерами таких моделей в статье служат \textit{Baseline} и \textit{Baseline++}.

\item \textbf{Мета-модель.} На известных классах обучается модель, способная быстро (за несколько шагов градиентного спуска) приспособиться к новым классам. Недостаток у этого класса тот же, что и у предыдущего - для постоянного обновления параметров модели на этапе тестирования необходимы значительные ресурсы. Примером такой модели в статье служит \textit{MAML}.

\item \textbf{Обучение на основе метрики.} Модель обучается создавать универсальные семантические представления изображений так, чтобы представления одного класса были ближе по некоторой метрике, чем представления разных классов. Такой подход лучше масштабируется, так как на этапе тестирования сама модель не обновляется. Так же работать с векторами признаков удобнее, чем с изображениями. Исходя из этих достоинств, именно этот класс решений рассматривается в данной работе, т. к. описанный ниже исследуемый сценарий предполагает обработку большого количества классов на этапе тестирования. Примерами решений этого класса в статье служат \textit{ProtoNet} и \textit{RelationNet}.


\end{itemize}

\chapter{Постановка задачи}

Основными задачами данной работы являются:
\begin{itemize}

\item \textbf {Создание сценария для проверки моделей на большом количестве классов.} Традиционно используемые в работах на тему FSL наборы данных имеют не так много классов (miniImageNet \cite{imagenet}, к примеру, всего имеет 100 классов), а модели чаще всего тестируются в условиях, когда выбор нужно сделать из 5 классов. В реальной жизни необходимо зачастую различать десятки или сотни классов в рамках одной задачи. Для того, чтобы протестировать модели в таких усложненных условиях, необходимо подготовить новый набор данных. Данная работа стремится показать, что многоклассовый сценарий отличается от традиционного с точки зрения наиболее эффективных способов решения, а следовательно требует отдельного рассмотрения как новый подвид Few-Shot Learning.

\item \textbf {Разработка программного обеспечения для обучения и тестирования моделей, реализация различных алгоритмов для FSL.} Для проведения большого числа экспериментов на различных наборах данных необходима  программная среда, позволяющая по-разному конфигурировать модели, автоматически сохранять результаты экспериментов и обученные модели.

\item \textbf {Выявление наиболее эффективных методов для различных случаев.} В результате работы будет установлено, какие комбинации моделей и алгоритмов лучше всего работают для того или иного подвида Few-Shot Learning.

\end{itemize}

\chapter{Методика}

\section {Общие обозначения и определения}

Для удобства введем некоторые обозначения и с их помощью сформулируем задачу более конкретно. Пусть \textit{датасет} $D$ - множество пар $(x_i, y_i)$, где $x_i$ - \textit{изображение} из данного датасета, а $y_i$ - \textit{класс} этого изображения. \textit{Множество всех классов датасета} $C = \{y_i\}$, а \textit{количество различных классов} в датасете - $n_{classes} = |C|$. Общее количество элементов в датасете $N = |D|$. \\

Задача Few-Shot Learning характеризуется двумя параметрами: количеством классов $n$ количеством примеров на класс $k$. Такая задача называется \textit{n-way k-shot learning}. \\

Основной используемый датасет $D_{base}$ делится на два непересекающихся по элементам и классам датасета $D_{train}$ и $D_{test}$ ($D_{train} \cup D_{test} = D_{base}$; $ C_{train} \cap C_{test} = \varnothing $). На $D_{train}$ модель обучается, выделяя признаки, необходимые для классификации новых изображений; $D_{test}$ используется только на этапе тестирования решения. \\

В процессе обучения/оценки модели из датасетов случайным образом выбираются \textit{задания}. Задание состоит из \textit{набора образцов} $S$ - датасета с $n$ классами и $k$ примерами на каждый класс (всего в нем $n \times k$ элементов) и \textit{набора запросов} $Q$ - набора изображений, для которых модель должна предсказать класс, основываясь на примерах из $S$. На этапе тренировки модели предъявляются задания из $D_{train}$, на этапе тестирования - задания из $D_{test}$.

\section {Алгоритмы решения}

% \subsection {Основа}

В данной работе рассматриваются решения, основанные на т. н. ProtoNet \cite{closerlook}. Основной частью такой модели является сверточная нейронная сеть - представим ее как функцию $f_{\theta}$, где $\theta$ - обучаемые параметры сети. $f_{\theta}$ принимает на вход изображение $x_i$ и преобразовывает его в вектор признаков: $\hat{x}_i = f_{\theta}(x_i)$. Необходимо заметить, что данные, возвращаемые $f_{\theta}$ представляют собой \textit{карты признаков}, а значит имеют два пространственных измерения, помимо измерения признаков - для превращения этого трехмерного тензора в одномерный вектор все его измерения объединяются в одно (с потерей пространственной информации), однако в описанном далее DFMN будут использоваться именно карты признаков, не превращенные в вектор.  В задании $T$ для каждого класса $c \in C_T$ вычисляется вектор-прототип $\langle  \hat{x}_c \rangle$ - путем усреднения векторов признаков для изображений этого класса, входящих в $S_T$. Пусть $d(\bar{a}, \bar{b})$ - используемая в модели функция сходства двух векторов (чем слабее векторы различаются, тем больше значение функции; примером такой функции служит Евклидово расстояние, умноженное на -1: $d(\bar{a}, \bar{b}) = -\sqrt{{(\bar{a} - \bar{b})}^2}$ ). Для каждого $ \hat{x}_q  $ вектора признаков изображения - запроса $x_q \in Q_T$ выполняется поочередное сравнение со всеми прототипами $\langle \hat{x}_c \rangle : \forall c \in C_T$. Таким образом для каждого класса мы получаем число, характеризующее степень <<похожести>> запроса на этот класс. Для $T \leftarrow D_{train}$, используя функцию потерь (в данном случае - перекрестную энтропию) вычисляются градиенты и обновляются параметры сети $\theta$. Для $T \subset D_{test}$ к полученным числам применяется функция \textit{softmax}, в результате чего на выходе модели получаются вероятности принадлежности запроса каждому из классов. \\

Это базовый алгоритм решения может быть модифицирован в нескольких местах. В данной работе рассматриваются 3 вида модификаций: описание каждого вида приведено ниже.

\subsection{Функции потерь}
При обучении нейросетей на малом количестве данных может возникать проблема \textit{переобучения} - ситуация, когда нейросеть <<запоминает>> тренировочные примеры, выделяет недостаточно обобщенные признаки, и на тестовых изображениях точность оказывается сильно ниже, чем на тренировочных. Для борьбы с переобучением используются т. н. \textit{вспомогательные задачи} - на этапе тренировки та же нейронная сеть $f_{\theta}$ параллельно с основной задачей используется для решения дополнительных - так модель меньше <<фокусируется>> на малочисленных обучающих примерах и получается более универсальной. При использовании вспомогательных задач вычисляются дополнительные функций потерь, которые складываются с основной (возможно, с коэффициентами) перед вычислением градиентов и обновлением $\theta$. Особенностью этого класса модификаций является то, что они влияют только на процесс обучения - при тестировании модель, обученная с вспомогательными задачами, работает по тому же алгоритму, что и обученная без них. Далее описаны вспомогательные задачи, использованные в рамках данной работы. \\

\textbf {Dense Feature-Matching network (DFMN) \cite{dfmn}.} Задания $T$, получаемые моделью при обучении содержат в себе мало классов и примеров на класс. В то же время, на этапе обучения нам доступен весь датасет $D_{train}$. Чтобы задействовать все данные, метод DFMN предполагает создания для каждого класса из $D_{train}$ \textit{глобального} обучаемого вектора-прототипа. Эти векторы обновляются вместе с другими параметрами модели, поэтому их значения доступны вне зависимости от конкретного задания в течение всего обучения. Получая задание $T$ модель, помимо стандартной FSL классификации на основе $S_{T}$ осуществляет в качестве вспомогательной задачи классификацию на основе этих глобальных прототипов (используя Евклидово сходство). Функции потерь для результатов двух классификаций складываются (при этом значение основной функции домножается на константу 0.2).  Еще одной особенностью данного метода является то, что хотя карты признаков, полученные от нейросети $f_{\theta}$ имеют пространственное измерение, глобальный прототипы его не имеют. Вспомогательная классификация осуществляется для \textit{векторов признаков от всех пикселей} карт признаков изображений - запросов. Например, если $f_{\theta}$ возвращает трехмерный тензор $m$ размера $H \times W \times K$, то $m_{i, j} \; (0 \le i < H; \; 0 \le j < W)$ - это вектор размера $K$. Глобальные прототипы - тоже векторы размера $K$, классификация происходит для всех $m_{i, j} \; (0 \le i < H; \; 0 \le j < W)$. В остальных частях модели значения, полученные из $f_{\theta}$ все так же представляются в виде одномерного вектора размера $H \cdot W \cdot K$. \\

\textbf {Распознавание поворота \cite{rotation}.} Для этой вспомогательной задачи создается дополнительная нейронная сеть - классификатор (ее архитектура описана в приложении) $g_{\phi}$, где $\phi$ - параметры. $g_{\phi}$ принимает на вход векторы признаков от $f_{\theta}$ и возвращает вектор из 4 чисел, предсказывающих, насколько вероятно, что картинка повернута на один из четырех углов - $0^{\circ}$, $90^{\circ}$, $180^{\circ}$, $270^{\circ}$. Таким образом, распознавание поворота - традиционная задача классификации изображений по 4 классам. Во время итерации обучения на задании $T$ изображения этого задания $x_{i}$ случайным образом поворачиваются на один из указанных углов, а затем подаются на вход композиции функций $g_{\phi}(f_{\theta}(x_i))$, от полученного на выходе вектора считается функция потерь (стандартная для классификации перекрестная энтропия), которая затем складывается с основной функцией потерь. По этой сумме вычисляются градиенты и обновляются $\theta$ и $\phi$.

\subsection{Преобразование прототипов}
После получения прототипов по алгоритму, описанному выше, к полученным векторам можно применять различные преобразования. Такие преобразования должны быть типа <<набор в набор>>, то есть принимать на вход и возвращать набор векторов-прототипов. В рамках данной работы рассматривается одно такое преобразование, его описание приведено ниже.\\

\textbf {FEAT \cite{setset}}. Это преобразование основано на алгоритме \textit{трансформер}. Трансформер - разработанная в 2017 году архитектура нейронных сетей, предназначенная для обработки наборов данных, в которых необходимо находить взаимосвязи между отдельными элементами. Модели на основе этой архитектуры активно применяются сейчас в задачах обработки естественных языков: например, на трансформере основана GPT-3 - самая продвинутая на данный момент модель для обработки естественного языка. \\

В моделях для решения FSL используется часть архитектуры трансформер под названием \textit{механизм самовнимания}, который позволяет менять значения прототипа класса, учитывая информацию, полученную из прототипов других классов. Такой метод для Few-Shot Learning называется \textit{FEAT - Few-Shot Embedding Adaptation with Transformer}. Для работы механизма необходимо добавить в обучаемые параметры модели три квадратные матрицы Q, K, V; причем размеры матриц должны совпадать с количеством элементов в векторе прототипа. Из вычисленного по описанным выше правилам прототипа класса $\langle \tilde{x}_c \rangle$ путем умножения на соответствующие матрицы получаются 3 вектора - $\langle \hat{x}_c \rangle \cdot Q = q_{c}$, $\langle \hat{x}_c \rangle \cdot K = k_{c}$ и $\langle \hat{x}_c \rangle \cdot V = v_{c}$ (т. н. запрос, ключ и значение). Вектор \textit{внимания} для запроса $q_{c}$ вычисляется как: $$a_{c} = softmax\left(\frac{q_{c} \cdot k_{j}}{\sqrt{n_{dim}}} \; | \;  \forall j \in C \right)$$ где $n_{dim}$ - размер векторов прототипов. Новое значение прототипов вычисляется как произведение вектора внимания на матрицу, являющуюся вектором векторов - значений: $$\langle \tilde{x}_c \rangle =\left(  a_{c_j} \cdot  v_{j}  \; | \;  \forall j \in C  \right)$$ то есть новый прототип равен взвешенной сумме векторов - значений $q_{c}$, с коэффициентами из вектора внимания. Эти новые прототипы затем проходят через один обучаемый полносвязный линейный слой (т. е. умножаются на обучаемую матрицу весов), после чего к ним применяется dropout. Для получения итоговых векторов-прототипов классов, которые будут использоваться далее в решении FSL новые прототипы $Dropout \left(Linear \left( \langle \tilde{x}_c \rangle \right) \right)$ складываются со старыми $\langle \tilde{x}_c \rangle$, полученные итоговые векторы-прототипы нормализуются.

\subsection{Функции сходства}

В описании алгоритма решения FSL была упомянута функция схожести $d(\bar{a}, \bar{b})$, характеризующая степени близости векторов $\bar{a}$ и $\bar{b}$. Эта функция может быть разной - в данной работе рассматриваются 3 ее варианта, которые описаны ниже. \\

\textbf {Евклидово сходство.} Уже упомянутая наиболее очевидная функция схожести, основанная на Евклидовом расстоянии (взятом со знаком -). Формула: $$d_{euclidean}(\bar{a}, \bar{b}) = -\sqrt{{(\bar{a} - \bar{b})}^2}$$.\\

\textbf {Масштабированное нормированное Евклидово сходство (Scaled euclidean) \cite{dfmn}.}  Описанная в той же работе, что и DFMN, данная функция сходства построена на базе все того же Евклидова сходства. Однако, в формулу внесены два дополнения: во-первых векторы нормируются по длине, во-вторых уже нормированные векторы делятся на коэффициент, вычисляемый отдельно для каждого вектора при помощи отдельной нейросети $s_{\psi}$ (архитектура этой сети описана в приложении), где $\psi$ - параметры. Таким образом, итоговая формула выглядит так: $$d_{scaled\_euclidean}(\bar{a}, \bar{b}) =  -\sqrt{{ \left(\frac{\bar{a}}{s_{\psi}(\bar{a}) \cdot |\bar{a}|} - \frac{\bar{b}}{s_{\psi}(\bar{b}) \cdot |\bar{b}|}\right)}^2}$$  Параметры $\psi$ обновляются в процессе обучения вместе с остальными параметрами модели.\\

\textbf {SEN (Squared root of the Euclidean distance and the Norm distance) \cite{sen}.} Эта функция сходства так же основана на Евклидовом сходстве: в данном случае под знак корня в формулу обычного Евклидова расстояния добавляется квадрат разности длин векторов с коэффициентом $\epsilon$. Итоговая формула выглядит так:  $$d_{SEN}(\bar{a}, \bar{b}) = -\sqrt{{ \left( \bar{a} - \bar{b} \right)}^2 + \epsilon \cdot \left( |\bar{a}| -  |\bar{b}| \right)^2}$$ Значение $\epsilon$ во время обучения этом равно: $$\epsilon = \begin{cases} 1.0 & \textup{при сравнении вектора признаков запроса с прототипом правильного класса}  \\ -10^{-7} & \textup{при сравнении вектора признаков запроса с другими прототипами} \end{cases} $$ Таким образом, данная функция стимулирует модель преобразовывать изображения одного класса в векторы, имеющие одинаковый модуль (т. е. расположенные на гиперсфере в многомерном пространстве), а изображения разных классов - в векторы, имеющие различный модуль. При тестировании, когда метки, определяющие для запросов правильный класс недоступны, $\epsilon = 1.0$\\

\section {Данные}

Для обучения и оценки моделей, решающих задачу классификации изображений, необходимы большие наборы размеченных данных - датасетов. В данной работе было использовано два датасета, описания которых приведены ниже.\\

\textbf {MiniImageNet \cite{imagenet}.} Наиболее популярный у исследователей датасет для Few-Shot Learning. Является подмножеством ImageNet - основного датасета в классификации изображений. Состоит из 100 классов, по 600 примеров на каждый. В ходе обучения и тестирования выделяются 60 тренировочных классов, 20 классов для оценки во время тренировки и 20 классов для окончательной оценки модели. Как и в ImageNet, классы сильно различаются между собой: например, там представлены изображения птиц - юрков и в то же время тарелок для супа. Такой датасет требует от модели универсальности, но количество классов в нем ограничено, что стало причиной для поиска следующего датасета. \\

\textbf {MiniGoogleLandmarks.} Подмножество датасета GoogleLandmarks \cite{google}, собранное самостоятельно в рамках работы. Были случайным образом выбраны 4979 классов, каждый из которых представлен 10-20 примерами. Разбивается на 3000 классов для непосредственного обучения, 979 классов для оценки во время тренировки и 1000 классов для окончательной оценки модели. Все классы в этом датасете представляют собой архитектурные достопримечательности (памятники, здания), изображения - фотографии, сделанные с разных ракурсов в разное время. Классы в этом датасете не столь разнообразны, но их количество позволяет, например, реализовать сценарий, где при тестировании модель в каждом эпизоде классифицирует изображения - запросы по 100 классам. Особенностью этого набора данных, так же является то, что среди данных довольно часто встречаются нерелевантные изображения. Связано это с тем, что исходный датасет GoogleLandmarks во многом формировался на основе фотографий из Википедии, где в статье про архитектурные объекты могут так же встречаться фото табличек, планов и т. д. Такой <<естественный>> шум в данных приближает задачу к реальному миру.

\section {Сценарии и условия экспериментов}

Всего в данной работе рассматриваются 6 модификаций для модели ProtoNet. Методы из секций \textbf{Функции потерь} и \textbf{Преобразование прототипов} могут быть добавлены или не добавлены в модель, в то время как функцию сходства необходимо выбрать ровно одну. Число исследуемых моделей, таким образом $2^3 \cdot 3 = 24$.\\

Производительность каждой модели будет оценена в 5 сценариях:
\begin{itemize}
\item \textbf{1-shot} и \textbf{5-shot 5-way FSL на miniImageNet} - наиболее популярные сценарии в работах на данную тему при оценке общей производительности модели.

\item \textbf{5-shot 100-way FSL на miniGoogleLandmarks} - сценарий для оценки производительности модели в условиях, когда необходимо решить задачу с большим количеством классов и малым количеством примеров. Так как показатели алгоритмов в этих условиях сильно хуже, чем в случае 5-way miniImageNet, сценарии с еще меньшим количеством примеров (например, 1-shot) на класс не использовались.

\item \textbf{5-shot FSL с переносом опыта} - этот подвид FSL подразумевает обучение модели на одном датасете, а тестирование на другом - проверяется способность модели обобщать информацию и выделять признаки, неспецифичные для конкретного датасета. В данной работе рассматриваются 2 сценария из этого класса: обучение на miniImageNet, затем тестирование на miniGoogleLandmarks (100-way), и обучение на miniGoogleLandmarks, затем тестирование на miniImageNet (5-way). В первом случае, модель обученную на разнообразном датасете применяют к более однородному датасету, во втором - все происходит наоборот.

\end{itemize}

Вне зависимости от сценария обучение происходит на 15-way FSL. Это связано с тем, что использование большего числа классов при обучении, чем при тестировании дает лучший результат, однако обучение требует больше ресурсов, чем тестирование, следовательно невозможно обучать модель, например, на 100-way FSL. При выделении задания из датасета как во время тренировки, так и во время тестирования, в качестве Q берутся по 5 (или 3, если не хватает памяти) случайных изображений для каждого класса в S. При этом Q и S не пересекаются по изображениям. \\

Результаты модели вычисляются путем усреднения ее результатов на 1000 случайно сгенерированных заданиях из $D_{test}$. В качестве показателей используются 2 метрики - \textit{точность (accuracy)} и \textit{топ-3 точность (top-3 accuracy)}. Топ-3 точность аналогична обычной точности за исключением того, что считается, что модель дает правильный ответ в том случае, если правильный класс изображения находится среди 3-х наиболее вероятных классов по <<мнению>> модели (такая метрика может быть полезна в случае, если мы можем предложить пользователю нашей программы вручную выбрать из нескольких классов, например в рекомендательных системах или системах поиска). Для метрик указаны доверительные интервалы, равные утроенному стандартному отклонению. \\

Следует отметить, что в большинстве работ, посвященных теме Few-Shot Learning, используются стандартные архитектуры сверточных нейронных сетей. В нашем случае была выбрана архитектура \textit{Conv-4}, этот выбор был сделан исходя из доступной оперативной памяти видеокарты (4 GB на Nvidia 1050 Ti). Так как выбор данной архитектуры не является предметом исследования, описание Conv-4, а так же архитектур вспомогательных нейросетей, подробное описание всех этих архитектур помещено в \textbf{Приложение} \\.

Реализация всех моделей и алгоритмов, описанных в данной работе, доступна по ссылке \url{https://github.com/petrtsv/few_shot_learning_study}

\chapter{Результаты экспериментов}

Для краткости в этом разделе будут приведены только 5 наилучших моделей для каждого сценария. Таблицы со всеми проведенными экспериментами (в сумме по сценариям 120 экспериментов) находятся в  \textbf{Приложении}.

\begin{table}[H]
\begin{adjustbox}{center}
\begin{tabular}{| r | c c c c | c |  c | }
\hline
    & Rotation task   & DFMN   & FEAT   & Distance         & Accuracy         & Top-3 accuracy   \\
\hline
  1 & +               & -      & +      & SEN              & $0.550 \pm 0.013$ & $0.894 \pm 0.008$ \\
\hline
  2 & +               & -      & +      & Euclidean        & $0.549 \pm 0.012$ & $0.889 \pm 0.008$ \\
\hline
  3 & -               & -      & +      & SEN              & $0.548 \pm 0.012$ & $0.895 \pm 0.008$ \\
\hline
  4 & -               & +      & +      & SEN              & $0.548 \pm 0.012$ & $0.894 \pm 0.008$ \\
\hline
  5 & -               & +      & +      & Euclidean        & $0.547 \pm 0.013$ & $0.889 \pm 0.008$ \\
\hline
\end{tabular}
\end{adjustbox}
	\caption{\centering 1-shot FSL на miniImageNet (5-way)}
\end{table}


\begin{table}[H]
\begin{adjustbox}{center}
\begin{tabular}{| r | c c c c | c |  c | }
\hline
    & Rotation task   & DFMN   & FEAT   & Distance         & Accuracy         & Top-3 accuracy   \\
    
    \hline
  1 & -               & +      & -      & Scaled euclidean & $0.703 \pm 0.011$ & $0.955 \pm 0.004$ \\
    \hline
  2 & +               & -      & +      & Euclidean        & $0.700 \pm 0.011$ & $0.954 \pm 0.005$ \\
    \hline
  3 & +               & -      & +      & Scaled euclidean & $0.700 \pm 0.011$ & $0.953 \pm 0.005$ \\
    \hline
  4 & -               & +      & -      & SEN              & $0.697 \pm 0.011$ & $0.950 \pm 0.005$ \\
    \hline
  5 & -               & +      & -      & Euclidean        & $0.696 \pm 0.011$ & $0.951 \pm 0.005$ \\
\hline
\end{tabular}
\end{adjustbox}
\caption{\centering 5-shot FSL на miniImageNet (5-way)}
\end{table}
 
  \begin{table}[H]
\begin{adjustbox}{center}
\begin{tabular}{| r | c c c c | c |  c | }
\hline
    & Rotation task   & DFMN   & FEAT   & Distance         & Accuracy         & Top-3 accuracy   \\
    \hline
  1 & -               & -      & +      & Euclidean        & $0.403 \pm 0.003$ & $0.565 \pm 0.003$ \\
    \hline
  2 & -               & +      & -      & Euclidean        & $0.398 \pm 0.003$ & $0.555 \pm 0.003$ \\
    \hline
  3 & +               & -      & +      & Euclidean        & $0.398 \pm 0.003$ & $0.559 \pm 0.003$ \\
    \hline
  4 & +               & -      & +      & SEN              & $0.397 \pm 0.003$ & $0.558 \pm 0.003$ \\
    \hline
  5 & -               & -      & -      & SEN              & $0.395 \pm 0.003$ & $0.556 \pm 0.003$ \\
\hline
\end{tabular}
\end{adjustbox}
\caption{\centering 5-shot FSL на miniGoogleLandmarks (100-way)}
\end{table}
 
 \begin{table}[H]
\begin{adjustbox}{center}
\begin{tabular}{| r | c c c c | c |  c | }
\hline
    & Rotation task   & DFMN   & FEAT   & Distance         & Accuracy         & Top-3 accuracy   \\
    \hline
  1 & -               & +      & -      & Scaled euclidean & $0.298 \pm 0.003$ & $0.442 \pm 0.003$ \\
    \hline
  2 & +               & +      & -      & Scaled euclidean & $0.296 \pm 0.003$ & $0.441 \pm 0.003$ \\
    \hline
  3 & -               & +      & -      & Euclidean        & $0.295 \pm 0.003$ & $0.436 \pm 0.003$ \\
    \hline
  4 & +               & +      & -      & Euclidean        & $0.291 \pm 0.003$ & $0.434 \pm 0.003$ \\
    \hline
  5 & +               & +      & -      & SEN              & $0.291 \pm 0.003$ & $0.433 \pm 0.003$ \\
\hline
\end{tabular}
\end{adjustbox}
\caption{\centering 5-shot FSL; обучен на miniImageNet, протестирован на miniGoogleLandmarks (100-way)}
\end{table}

\begin{table}[H]
\begin{adjustbox}{center}
\begin{tabular}{| r | c c c c | c |  c | }
\hline
    & Rotation task   & DFMN   & FEAT   & Distance         & Accuracy         & Top-3 accuracy   \\
    \hline
  1 & +               & -      & +      & Euclidean        & $0.562 \pm 0.011$ & $0.897 \pm 0.007$ \\
    \hline
  2 & -               & -      & +      & Euclidean        & $0.562 \pm 0.011$ & $0.896 \pm 0.007$ \\
    \hline
  3 & +               & -      & -      & SEN              & $0.561 \pm 0.012$ & $0.897 \pm 0.007$ \\
    \hline
  4 & -               & -      & -      & Euclidean        & $0.561 \pm 0.011$ & $0.895 \pm 0.007$ \\
    \hline
  5 & +               & +      & -      & SEN              & $0.558 \pm 0.012$ & $0.894 \pm 0.007$ \\
\hline
\end{tabular}
\end{adjustbox}
\caption{\centering 5-shot FSL; обучен на miniGoogleLandmarks, протестирован на miniImageNet (5-way)}
\end{table}

Из полученных результатов видно, что модели, дающий наилучший (или хотя бы близкий к наилучшему) результат на всех сценариях не существует - для разных ситуации нужно выбирать разные алгоритмы. \\

Анализируя результаты наиболее интересных в контексте данной работы сценариев - тех, где модель обучалась на miniGoogleLandmarks мы можем заметить, что наилучший результат показывают модели, использующие более простые функции сходства - Евклидово и SEN, не имеющие дополнительных обучаемых параметров, в отличие от Scaled euclidean. В 5-shot сценариях с обучением на miniImageNet, напротив, модели со Scaled euclidean находятся на верхних строчках списка. Это различие демонстрирует, что сценарии Few-Shot Learning с большим количеством классов имеют определенную специфику по отношению к традиционным сценариям и должны рассматриваться как отдельная подзадача. \\

Стоит так же отметить, что комбинация методов, предложенных в различных работах различными исследователи хоть и показывает зачастую результаты, близкие к наилучшим,собственно  наилучший результат показывает только в 1-shot miniImageNet сценарии. Вероятно, более тонкая настройка модулей при их совмещении позволит улучшить показатели таких <<комплексных>> моделей.


\chapter{Вывод}

Полученные в данной работе экспериментальные результаты позволят в дальнейшем выбирать наиболее оптимальные модели для решения той или иной задачи. \textbf{Точность, достигнутая на miniImageNet (5-way) составляет 55.0\% и 70.3\% для 1-shot и 5-shot соответственно; на 5-shot miniGoogleLandmarks (100-way) была достигнута точность 40.3\% при топ-3 точности 56.5\%} Так же было показано, что созданный в ходе работы сценарий для многоклассового Few-Shot Learning на основе датасета GoogleLandmarks \cite{google} является самостоятельной подзадачей, требующей отдельного изучения и решения. \\

В ходе работы была разработана программа, позволяющая обучать, тестировать и применять модели для Few-Shot Learning, а так же сохранены обученные модели, которые могут быть использованы для решения практических прикладных задач. Исходный код доступен по ссылке: \url{https://github.com/petrtsv/few_shot_learning_study}\\

Исследования данной задачи можно продолжать в следующих направлениях: использование сетей с более глубокой архитектурой для повышения точности (с использованием б\'{о}льших вычислительных ресурсов); более детальное изучение способов совмещения различных методов решения FSL; разработка новых методов, специфичных для рассматриваемого сценария.

\bibliographystyle{unsrt}
\bibliography{bibliography}

\chapter{Приложение}

\section {Использованные архитектуры нейросетей}

В таблицах ниже \textit{n} обозначает количество признаков на выходе слоя, \textit{s} - stride, \textit{p} - padding, \textit{k} - размер ядра свертки (квадратного).

\begin{table}[H]
\begin{adjustbox}{center}
\begin{tabular}{| c | }
\hline
Слои сети \\
\hline
Convolutional(n=64, k=3, p=1, s=1) \\
\hline
BatchNorm \\
\hline
ReLU \\
\hline
MaxPool(k=2, s=2) \\
\hline
Convolutional(n=64, k=3, p=1, s=1) \\
\hline
BatchNorm \\
\hline
ReLU \\
\hline
MaxPool(k=2, s=2) \\
\hline
Convolutional(n=64, k=3, p=1, s=1) \\
\hline
BatchNorm \\
\hline
ReLU \\
\hline
MaxPool(k=2, s=2) \\
\hline
Convolutional(n=64, k=3, p=1, s=1) \\
\hline
BatchNorm \\
\hline
ReLU \\
\hline
MaxPool(k=2, s=2) \\
\hline
\end{tabular}
\end{adjustbox}
\caption{\centering $f_{\theta}$ - основная нейронная сеть. Архитектура Conv4 \cite{dfmn}}
\end{table}

\begin{table}[H]
\begin{adjustbox}{center}
\begin{tabular}{| c | }
\hline
Слои сети \\
\hline
Convolutional(n=1, k=3, p=0, s=1) \\
\hline
BatchNorm \\
\hline
ReLU \\
\hline
Flattening \\
\hline
Linear(n=1) \\
\hline
Softplus \\
\hline
\end{tabular}
\end{adjustbox}
\caption{\centering $s_{\psi}$ - нейронная сеть для масштабирования вектора признаков в Scaled Euclidean \cite{dfmn}}
\end{table}

\begin{table}[H]
\begin{adjustbox}{center}
\begin{tabular}{| c | }
\hline
Слои сети \\
\hline
Convolutional(n=128, k=3, p=1, s=1) \\
\hline
BatchNorm \\
\hline
ReLU \\
\hline
Convolutional(n=256, k=3, p=1, s=1) \\
\hline
BatchNorm \\
\hline
ReLU \\
\hline
Flattening \\
\hline
Linear(n=4) \\
\hline
\end{tabular}
\end{adjustbox}
\caption{\centering $g_{\phi}$ - вспомогательная нейронная сеть для классификации поворота \cite{rotation}}
\end{table}
\newpage
\section {Полные результаты экспериментов}

Здесь приведены полные таблицы со всеми результатами экспериментов.

\begin{table}[h!]
\begin{adjustbox}{center}
\begin{tabular}{| r | c c c c | c |  c | }
\hline
    & Rotation task   & DFMN   & FEAT   & Distance         & Accuracy         & Top-3 accuracy   \\
\hline
  1 & +               & -      & +      & SEN              & $0.550 \pm 0.013$ & $0.894 \pm 0.008$ \\
\hline
  2 & +               & -      & +      & Euclidean        & $0.549 \pm 0.012$ & $0.889 \pm 0.008$ \\
\hline
  3 & -               & -      & +      & SEN              & $0.548 \pm 0.012$ & $0.895 \pm 0.008$ \\
\hline
  4 & -               & +      & +      & SEN              & $0.548 \pm 0.012$ & $0.894 \pm 0.008$ \\
\hline
  5 & -               & +      & +      & Euclidean        & $0.547 \pm 0.013$ & $0.889 \pm 0.008$ \\
\hline
  6 & +               & -      & +      & Scaled euclidean & $0.546 \pm 0.013$ & $0.892 \pm 0.008$ \\
\hline
  7 & -               & -      & +      & Euclidean        & $0.546 \pm 0.013$ & $0.893 \pm 0.008$ \\
\hline
  8 & -               & -      & +      & Scaled euclidean & $0.544 \pm 0.012$ & $0.891 \pm 0.008$ \\
\hline
  9 & +               & +      & +      & Euclidean        & $0.544 \pm 0.012$ & $0.887 \pm 0.008$ \\
\hline
 10 & -               & +      & -      & Scaled euclidean & $0.542 \pm 0.012$ & $0.888 \pm 0.008$ \\
\hline
 11 & +               & +      & +      & SEN              & $0.530 \pm 0.012$ & $0.883 \pm 0.008$ \\
\hline
 12 & -               & +      & +      & Scaled euclidean & $0.529 \pm 0.012$ & $0.881 \pm 0.008$ \\
\hline
 13 & +               & +      & +      & Scaled euclidean & $0.529 \pm 0.012$ & $0.873 \pm 0.008$ \\
\hline
 14 & -               & +      & -      & Euclidean        & $0.526 \pm 0.012$ & $0.881 \pm 0.008$ \\
\hline
 15 & +               & -      & -      & Scaled euclidean & $0.526 \pm 0.012$ & $0.878 \pm 0.008$ \\
\hline
 16 & +               & +      & -      & Scaled euclidean & $0.525 \pm 0.012$ & $0.877 \pm 0.008$ \\
\hline
 17 & -               & -      & -      & Scaled euclidean & $0.520 \pm 0.012$ & $0.875 \pm 0.008$ \\
\hline
 18 & -               & +      & -      & SEN              & $0.519 \pm 0.012$ & $0.876 \pm 0.008$ \\
\hline
 19 & +               & +      & -      & SEN              & $0.510 \pm 0.012$ & $0.871 \pm 0.008$ \\
\hline
 20 & +               & -      & -      & SEN              & $0.510 \pm 0.012$ & $0.877 \pm 0.008$ \\
\hline
 21 & +               & +      & -      & Euclidean        & $0.509 \pm 0.012$ & $0.869 \pm 0.008$ \\
\hline
 22 & +               & -      & -      & Euclidean        & $0.509 \pm 0.012$ & $0.870 \pm 0.008$ \\
\hline
 23 & -               & -      & -      & SEN              & $0.508 \pm 0.012$ & $0.872 \pm 0.008$ \\
\hline
 24 & -               & -      & -      & Euclidean        & $0.501 \pm 0.012$ & $0.871 \pm 0.008$ \\
\hline
\end{tabular}
\end{adjustbox}
	\caption{\centering 1-shot FSL на miniImageNet (5-way)}
\end{table}


\begin{table}[h!]
\begin{adjustbox}{center}
\begin{tabular}{| r | c c c c | c |  c | }
\hline
    & Rotation task   & DFMN   & FEAT   & Distance         & Accuracy         & Top-3 accuracy   \\
    
    \hline
  1 & -               & +      & -      & Scaled euclidean & $0.703 \pm 0.011$ & $0.955 \pm 0.004$ \\
    \hline
  2 & +               & -      & +      & Euclidean        & $0.700 \pm 0.011$ & $0.954 \pm 0.005$ \\
    \hline
  3 & +               & -      & +      & Scaled euclidean & $0.700 \pm 0.011$ & $0.953 \pm 0.005$ \\
    \hline
  4 & -               & +      & -      & SEN              & $0.697 \pm 0.011$ & $0.950 \pm 0.005$ \\
    \hline
  5 & -               & +      & -      & Euclidean        & $0.696 \pm 0.011$ & $0.951 \pm 0.005$ \\
    \hline
  6 & -               & -      & +      & Euclidean        & $0.694 \pm 0.011$ & $0.950 \pm 0.005$ \\
    \hline
  7 & +               & -      & +      & SEN              & $0.693 \pm 0.011$ & $0.951 \pm 0.005$ \\
    \hline
  8 & -               & +      & +      & Euclidean        & $0.692 \pm 0.011$ & $0.952 \pm 0.005$ \\
    \hline
  9 & -               & +      & +      & SEN              & $0.690 \pm 0.011$ & $0.951 \pm 0.005$ \\
    \hline
 10 & +               & +      & -      & Scaled euclidean & $0.690 \pm 0.011$ & $0.950 \pm 0.005$ \\
    \hline
 11 & +               & -      & -      & SEN              & $0.688 \pm 0.011$ & $0.947 \pm 0.005$ \\
    \hline
 12 & +               & -      & -      & Euclidean        & $0.686 \pm 0.011$ & $0.947 \pm 0.005$ \\
    \hline
 13 & -               & -      & +      & SEN              & $0.685 \pm 0.011$ & $0.949 \pm 0.005$ \\
    \hline
 14 & -               & +      & +      & Scaled euclidean & $0.685 \pm 0.011$ & $0.949 \pm 0.005$ \\
    \hline
 15 & +               & +      & +      & SEN              & $0.684 \pm 0.011$ & $0.949 \pm 0.005$ \\
    \hline
 16 & +               & +      & +      & Euclidean        & $0.683 \pm 0.011$ & $0.948 \pm 0.005$ \\
    \hline
 17 & +               & +      & -      & SEN              & $0.680 \pm 0.011$ & $0.947 \pm 0.005$ \\
    \hline
 18 & -               & -      & -      & SEN              & $0.679 \pm 0.011$ & $0.946 \pm 0.005$ \\
    \hline
 19 & +               & +      & -      & Euclidean        & $0.678 \pm 0.011$ & $0.947 \pm 0.005$ \\
    \hline
 20 & +               & -      & -      & Scaled euclidean & $0.678 \pm 0.011$ & $0.945 \pm 0.005$ \\
    \hline
 21 & -               & -      & -      & Scaled euclidean & $0.677 \pm 0.011$ & $0.947 \pm 0.005$ \\
    \hline
 22 & -               & -      & -      & Euclidean        & $0.677 \pm 0.011$ & $0.945 \pm 0.005$ \\
    \hline
 23 & -               & -      & +      & Scaled euclidean & $0.669 \pm 0.012$ & $0.943 \pm 0.005$ \\
    \hline
 24 & +               & +      & +      & Scaled euclidean & $0.654 \pm 0.011$ & $0.932 \pm 0.006$ \\
\hline
\end{tabular}
\end{adjustbox}
\caption{\centering 5-shot FSL на miniImageNet (5-way)}
\end{table}
 
 \begin{table}[h!]
\begin{adjustbox}{center}
\begin{tabular}{| r | c c c c | c |  c | }
\hline
    & Rotation task   & DFMN   & FEAT   & Distance         & Accuracy         & Top-3 accuracy   \\
    \hline
  1 & -               & +      & -      & Scaled euclidean & $0.298 \pm 0.003$ & $0.442 \pm 0.003$ \\
    \hline
  2 & +               & +      & -      & Scaled euclidean & $0.296 \pm 0.003$ & $0.441 \pm 0.003$ \\
    \hline
  3 & -               & +      & -      & Euclidean        & $0.295 \pm 0.003$ & $0.436 \pm 0.003$ \\
    \hline
  4 & +               & +      & -      & Euclidean        & $0.291 \pm 0.003$ & $0.434 \pm 0.003$ \\
    \hline
  5 & +               & +      & -      & SEN              & $0.291 \pm 0.003$ & $0.433 \pm 0.003$ \\
    \hline
  6 & -               & +      & -      & SEN              & $0.288 \pm 0.003$ & $0.432 \pm 0.003$ \\
    \hline
  7 & +               & +      & +      & Euclidean        & $0.285 \pm 0.003$ & $0.428 \pm 0.003$ \\
    \hline
  8 & +               & +      & +      & SEN              & $0.285 \pm 0.003$ & $0.429 \pm 0.003$ \\
    \hline
  9 & -               & +      & +      & Euclidean        & $0.285 \pm 0.003$ & $0.427 \pm 0.003$ \\
    \hline
 10 & -               & +      & +      & SEN              & $0.283 \pm 0.003$ & $0.427 \pm 0.003$ \\
    \hline
 11 & -               & +      & +      & Scaled euclidean & $0.275 \pm 0.003$ & $0.415 \pm 0.003$ \\
    \hline
 12 & +               & +      & +      & Scaled euclidean & $0.266 \pm 0.003$ & $0.406 \pm 0.003$ \\
    \hline
 13 & +               & -      & -      & SEN              & $0.261 \pm 0.003$ & $0.399 \pm 0.003$ \\
    \hline
 14 & +               & -      & +      & Scaled euclidean & $0.259 \pm 0.003$ & $0.397 \pm 0.003$ \\
    \hline
 15 & +               & -      & -      & Euclidean        & $0.258 \pm 0.003$ & $0.395 \pm 0.003$ \\
    \hline
 16 & +               & -      & -      & Scaled euclidean & $0.254 \pm 0.003$ & $0.390 \pm 0.003$ \\
    \hline
 17 & +               & -      & +      & SEN              & $0.253 \pm 0.003$ & $0.391 \pm 0.003$ \\
    \hline
 18 & +               & -      & +      & Euclidean        & $0.251 \pm 0.003$ & $0.388 \pm 0.003$ \\
    \hline
 19 & -               & -      & -      & Euclidean        & $0.250 \pm 0.003$ & $0.388 \pm 0.003$ \\
    \hline
 20 & -               & -      & -      & SEN              & $0.246 \pm 0.003$ & $0.382 \pm 0.003$ \\
    \hline
 21 & -               & -      & +      & Euclidean        & $0.235 \pm 0.003$ & $0.371 \pm 0.003$ \\
    \hline
 22 & -               & -      & +      & SEN              & $0.233 \pm 0.003$ & $0.367 \pm 0.003$ \\
    \hline
 23 & -               & -      & -      & Scaled euclidean & $0.221 \pm 0.002$ & $0.351 \pm 0.003$ \\
    \hline
 24 & -               & -      & +      & Scaled euclidean & $0.215 \pm 0.002$ & $0.347 \pm 0.003$ \\
\hline
\end{tabular}
\end{adjustbox}
\caption{\centering 5-shot FSL; обучен на miniImageNet, протестирован на miniGoogleLandmarks (100-way)}
\end{table}

\begin{table}[h!]
\begin{adjustbox}{center}
\begin{tabular}{| r | c c c c | c |  c | }
\hline
    & Rotation task   & DFMN   & FEAT   & Distance         & Accuracy         & Top-3 accuracy   \\
    \hline
  1 & +               & -      & +      & Euclidean        & $0.562 \pm 0.011$ & $0.897 \pm 0.007$ \\
    \hline
  2 & -               & -      & +      & Euclidean        & $0.562 \pm 0.011$ & $0.896 \pm 0.007$ \\
    \hline
  3 & +               & -      & -      & SEN              & $0.561 \pm 0.012$ & $0.897 \pm 0.007$ \\
    \hline
  4 & -               & -      & -      & Euclidean        & $0.561 \pm 0.011$ & $0.895 \pm 0.007$ \\
    \hline
  5 & +               & +      & -      & SEN              & $0.558 \pm 0.012$ & $0.894 \pm 0.007$ \\
    \hline
  6 & -               & +      & -      & Euclidean        & $0.557 \pm 0.012$ & $0.891 \pm 0.007$ \\
    \hline
  7 & +               & -      & -      & Euclidean        & $0.557 \pm 0.012$ & $0.898 \pm 0.007$ \\
    \hline
  8 & +               & -      & +      & SEN              & $0.556 \pm 0.011$ & $0.891 \pm 0.007$ \\
    \hline
  9 & +               & +      & -      & Euclidean        & $0.556 \pm 0.012$ & $0.890 \pm 0.007$ \\
    \hline
 10 & -               & +      & -      & SEN              & $0.555 \pm 0.011$ & $0.892 \pm 0.007$ \\
    \hline
 11 & +               & -      & +      & Scaled euclidean & $0.555 \pm 0.011$ & $0.892 \pm 0.007$ \\
    \hline
 12 & +               & -      & -      & Scaled euclidean & $0.555 \pm 0.011$ & $0.892 \pm 0.007$ \\
    \hline
 13 & -               & -      & +      & SEN              & $0.554 \pm 0.012$ & $0.894 \pm 0.007$ \\
    \hline
 14 & +               & +      & -      & Scaled euclidean & $0.550 \pm 0.012$ & $0.890 \pm 0.007$ \\
    \hline
 15 & +               & +      & +      & Euclidean        & $0.550 \pm 0.012$ & $0.888 \pm 0.007$ \\
    \hline
 16 & -               & -      & -      & SEN              & $0.549 \pm 0.011$ & $0.889 \pm 0.007$ \\
    \hline
 17 & -               & +      & +      & SEN              & $0.546 \pm 0.011$ & $0.885 \pm 0.007$ \\
    \hline
 18 & -               & -      & +      & Scaled euclidean & $0.545 \pm 0.011$ & $0.890 \pm 0.007$ \\
    \hline
 19 & +               & +      & +      & SEN              & $0.544 \pm 0.012$ & $0.885 \pm 0.007$ \\
    \hline
 20 & +               & +      & +      & Scaled euclidean & $0.541 \pm 0.012$ & $0.885 \pm 0.007$ \\
    \hline
 21 & -               & +      & -      & Scaled euclidean & $0.541 \pm 0.012$ & $0.888 \pm 0.007$ \\
    \hline
 22 & -               & +      & +      & Euclidean        & $0.541 \pm 0.011$ & $0.884 \pm 0.007$ \\
    \hline
 23 & -               & +      & +      & Scaled euclidean & $0.541 \pm 0.011$ & $0.885 \pm 0.007$ \\
    \hline
 24 & -               & -      & -      & Scaled euclidean & $0.536 \pm 0.011$ & $0.881 \pm 0.007$ \\
\hline
\end{tabular}
\end{adjustbox}
\caption{\centering 5-shot FSL; обучен на miniGoogleLandmarks, протестирован на miniImageNet (5-way)}
\end{table}
 
 \begin{table}[h!]
\begin{adjustbox}{center}
\begin{tabular}{| r | c c c c | c |  c | }
\hline
    & Rotation task   & DFMN   & FEAT   & Distance         & Accuracy         & Top-3 accuracy   \\
    \hline
  1 & -               & -      & +      & Euclidean        & $0.403 \pm 0.003$ & $0.565 \pm 0.003$ \\
    \hline
  2 & -               & +      & -      & Euclidean        & $0.398 \pm 0.003$ & $0.555 \pm 0.003$ \\
    \hline
  3 & +               & -      & +      & Euclidean        & $0.398 \pm 0.003$ & $0.559 \pm 0.003$ \\
    \hline
  4 & +               & -      & +      & SEN              & $0.397 \pm 0.003$ & $0.558 \pm 0.003$ \\
    \hline
  5 & -               & -      & -      & SEN              & $0.395 \pm 0.003$ & $0.556 \pm 0.003$ \\
    \hline
  6 & -               & -      & +      & SEN              & $0.395 \pm 0.003$ & $0.558 \pm 0.003$ \\
    \hline
  7 & +               & -      & -      & Euclidean        & $0.392 \pm 0.003$ & $0.551 \pm 0.003$ \\
    \hline
  8 & +               & -      & -      & SEN              & $0.390 \pm 0.003$ & $0.549 \pm 0.003$ \\
    \hline
  9 & -               & -      & -      & Euclidean        & $0.390 \pm 0.003$ & $0.549 \pm 0.003$ \\
    \hline
 10 & +               & -      & +      & Scaled euclidean & $0.389 \pm 0.003$ & $0.546 \pm 0.003$ \\
    \hline
 11 & -               & +      & -      & SEN              & $0.389 \pm 0.003$ & $0.549 \pm 0.003$ \\
    \hline
 12 & +               & +      & -      & SEN              & $0.386 \pm 0.003$ & $0.544 \pm 0.003$ \\
    \hline
 13 & +               & +      & -      & Euclidean        & $0.386 \pm 0.003$ & $0.540 \pm 0.003$ \\
    \hline
 14 & -               & -      & +      & Scaled euclidean & $0.385 \pm 0.003$ & $0.544 \pm 0.003$ \\
    \hline
 15 & +               & -      & -      & Scaled euclidean & $0.382 \pm 0.003$ & $0.539 \pm 0.003$ \\
    \hline
 16 & -               & -      & -      & Scaled euclidean & $0.376 \pm 0.003$ & $0.532 \pm 0.003$ \\
    \hline
 17 & +               & +      & +      & Euclidean        & $0.376 \pm 0.003$ & $0.537 \pm 0.003$ \\
    \hline
 18 & -               & +      & -      & Scaled euclidean & $0.375 \pm 0.003$ & $0.537 \pm 0.003$ \\
    \hline
 19 & -               & +      & +      & SEN              & $0.372 \pm 0.003$ & $0.534 \pm 0.003$ \\
    \hline
 20 & -               & +      & +      & Scaled euclidean & $0.372 \pm 0.003$ & $0.533 \pm 0.003$ \\
    \hline
 21 & -               & +      & +      & Euclidean        & $0.372 \pm 0.003$ & $0.533 \pm 0.003$ \\
    \hline
 22 & +               & +      & -      & Scaled euclidean & $0.369 \pm 0.003$ & $0.530 \pm 0.003$ \\
    \hline
 23 & +               & +      & +      & SEN              & $0.365 \pm 0.003$ & $0.526 \pm 0.003$ \\
    \hline
 24 & +               & +      & +      & Scaled euclidean & $0.362 \pm 0.003$ & $0.523 \pm 0.003$ \\
\hline
\end{tabular}
\end{adjustbox}
\caption{\centering 5-shot FSL на miniGoogleLandmarks (100-way)}
\end{table}
 
 
\end{document}